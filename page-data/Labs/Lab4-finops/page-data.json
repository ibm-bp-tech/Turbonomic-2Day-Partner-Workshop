{
    "componentChunkName": "component---src-pages-labs-lab-4-finops-mdx",
    "path": "/Labs/Lab4-finops/",
    "result": {"pageContext":{"frontmatter":{"title":"Lab4-finops"},"relativePagePath":"/Labs/Lab4-finops.mdx","titleType":"page","MdxNode":{"id":"5ad85a46-15c5-560f-8914-bc6231196d96","children":[],"parent":"cc34ee44-170a-5a2e-8d1c-e1684c6f1883","internal":{"content":"---\ntitle: Lab4-finops\n---\nexport const Title = () => (\n  <span>\n    FinOps 4 - Optimizing storage resources <br />\n  </span>\n)\n;\n\n\n## Get a global view of storage consumption\nThere are three forms of cloud storage: object storage, file storage, and block storage. The bank’s cost optimization effort focuses on block storage, which functions like an external disk to the compute instance and provides low-latency state management for cloud workloads.\n\nAt a general level, there are two types of block storage: solid state drives (SSDs) and hard disk drives (HDDs). SSDs are good for low-latency, heavy IOPS types of workloads, whereas HDDs are good for high throughput sequential workloads.\n\nIt is important for the bank to choose a storage service based on the workload characteristics at hand. Some of the most common ways companies overspend on storage are:\n\n* Unused volumes: Compute instances are stopped, but the storage volumes are forgotten. This results in orphaned volumes, which then results in residual and accumulating costs.\n* Overprovisioning: Storage services are grossly oversized. For most cloud resources, you pay for what you provision, not for what you use.\n* Mismatched storage type: The storage choices are not appropriate for the requirements of the specific workload. For example, transaction processing is often best done on fast SSDs, whereas sequential workloads — like logging — are more compatible with cost-effective HDDs. This can result in either suboptimal performance or cost overruns.\n\nLet’s start exploring the storage optimization opportunities in this environment.\n\n1. Point out the Volume entity, as highlighted in the screenshot and narration below.\n\n![Lab4](images/FinOps14.png)\n\nBy looking at the ‘Volume’ entity in the global supply chain, we see there are about 1,000 storage volumes in this environment. Notice the color coding in the donuts: “green” means healthy, “yellow” represents efficiency recommendations (i.e., cost savings), and “red” represents performance recommendations (i.e., impact to the end user experience). Based on the proportion of green vs. yellow vs. red, the bank can see there are significant opportunities to improve the cost efficiency and performance of storage.\n\nLet’s drill down to better understand these cost reduction opportunities.\n\n2. Click the Volume entity, which will take you to the Storage Summary dashboard. **(May also appear as \"Volume Summary\")**\n\n![Lab4](images/FinOps14.png)\n\n3. Point out the details on the Storage Summary dashboard, as highlighted in the screenshot and narration below.\n\n![Lab4](images/FinOps15.png)\n\nThe ‘Storage Summary’ dashboard shows the number of volumes (1), total monthly cost of these volumes (2), and potential monthly savings that can be realized (3). The ‘Unattached Storage’ bar (4) shows that about 7-8% of storage is currently unattached.\n\nLet’s take a deeper look at the specific volumes that can be reclaimed.\n\n## Reclaim waste\n\n4. On the Potential Savings dashboard, click SHOW ALL.\n\n![Lab4](images/FinOps16.png)\n\n\n5. Select the AZURE tab (1). Under the DELETE section of the left navigation bar, click Volumes (2).\n\n![Lab4](images/FinOps17.png)\n\nThe dashboard identifies the bank’s storage volumes that are unattached, including the number of days they have gone unused. On cloud, the lifecycles of the storage volumes are not intentionally associated with the lifecycles of the compute instances. Volumes that are unattached for many days are good candidates to reclaim and gain some savings. The data for each cloud provider appears on a separate tab. This dashboard displays the bank’s potential savings from Azure, assuming they take all the recommended actions.\n\nTurbonomic eliminates the need to hop between various cloud provider consoles. For example, we could also conveniently analyze storage usage in AWS or GCP by simply clicking the appropriate tab.\n\n6. Select the AWS tab (1). Under the DELETE section of the left navigation bar, click Volumes (2).\n\n![Lab4](images/FinOps18.png)\n\nJust by switching tabs, the bank can now see the potential savings from AWS storage, assuming they take all the recommended actions.\nOn the AWS tab, select a row and click the corresponding DETAILS button (3).\n\n7. Point out the details under ACTION ESSENTIALS on the Action Details panel, as highlighted in the screenshot and narration below.\n\n![Lab4](images/FinOps19.png)\n\nThe Action Details panel provides the bank with supporting details behind the recommendation. Under the ‘Action Essentials’ section, it also shows whether the action can be taken immediately, whether downtime is required, and whether the action is manually reversible once taken. Click \"Execute Action.\"\n\nNow let’s examine the bank’s cost savings opportunities from moving volumes to alternate storage types that are a better fit for the workloads at hand.\n\n## Select the right type of storage for the workloads\n\nThe bank needs to choose the right storage volume for their workloads. Capacity and performance are two fundamental factors around which these choices should be made. We’ll see how even if wrong initial choices are made, the Turbonomic platform will detect these optimization and cost reduction opportunities using its continuous feedback loop.\n\n8. Under the SCALE category of the left navigation bar, select Volumes.\n\n![Lab4](images/FinOps20.png)\n\nWe can immediately see the various scale options, along with the bank’s projected savings.\n\n9. Click DETAILS on the first row.\n\n![Lab4](images/FinOps21.png)\n\n10. Point out the details on the Action Details panel, as highlighted in the screenshot and narration below.\n\n![Lab4](images/FinOps22.png)\n![Lab4](images/FinOps23.png)\n\nWe can see that this particular volume is underutilized from both IOPS (1) and throughput (2) perspectives. Based on the actual utilization pattern of this workload, Turbonomic’s analytics show that this workload does not need a GP3 and that the performance requirements of the workload can be met with a cheaper ST1 storage tier. This workload does not need the provisioned 3,000 IOPS and can get by with a much lower 130 IOPS (Second Screenshot). We therefore see that the storage capacity was overprovisioned, at a cost that was 8-9% too high. Turbonomic’s analytics engine computes the projected cost savings (3 - First screenshot).\n\nBy analyzing and understanding the data access patterns of their workloads, the bank can make cost-efficient trade-offs about their storage choices, including the storage type, capacity, and IOPS. Click \"Execute Action\"\n","type":"Mdx","contentDigest":"23b03e1778131f3b8b93699292c09aa9","owner":"gatsby-plugin-mdx","counter":338},"frontmatter":{"title":"Lab4-finops"},"exports":{},"rawBody":"---\ntitle: Lab4-finops\n---\nexport const Title = () => (\n  <span>\n    FinOps 4 - Optimizing storage resources <br />\n  </span>\n)\n;\n\n\n## Get a global view of storage consumption\nThere are three forms of cloud storage: object storage, file storage, and block storage. The bank’s cost optimization effort focuses on block storage, which functions like an external disk to the compute instance and provides low-latency state management for cloud workloads.\n\nAt a general level, there are two types of block storage: solid state drives (SSDs) and hard disk drives (HDDs). SSDs are good for low-latency, heavy IOPS types of workloads, whereas HDDs are good for high throughput sequential workloads.\n\nIt is important for the bank to choose a storage service based on the workload characteristics at hand. Some of the most common ways companies overspend on storage are:\n\n* Unused volumes: Compute instances are stopped, but the storage volumes are forgotten. This results in orphaned volumes, which then results in residual and accumulating costs.\n* Overprovisioning: Storage services are grossly oversized. For most cloud resources, you pay for what you provision, not for what you use.\n* Mismatched storage type: The storage choices are not appropriate for the requirements of the specific workload. For example, transaction processing is often best done on fast SSDs, whereas sequential workloads — like logging — are more compatible with cost-effective HDDs. This can result in either suboptimal performance or cost overruns.\n\nLet’s start exploring the storage optimization opportunities in this environment.\n\n1. Point out the Volume entity, as highlighted in the screenshot and narration below.\n\n![Lab4](images/FinOps14.png)\n\nBy looking at the ‘Volume’ entity in the global supply chain, we see there are about 1,000 storage volumes in this environment. Notice the color coding in the donuts: “green” means healthy, “yellow” represents efficiency recommendations (i.e., cost savings), and “red” represents performance recommendations (i.e., impact to the end user experience). Based on the proportion of green vs. yellow vs. red, the bank can see there are significant opportunities to improve the cost efficiency and performance of storage.\n\nLet’s drill down to better understand these cost reduction opportunities.\n\n2. Click the Volume entity, which will take you to the Storage Summary dashboard. **(May also appear as \"Volume Summary\")**\n\n![Lab4](images/FinOps14.png)\n\n3. Point out the details on the Storage Summary dashboard, as highlighted in the screenshot and narration below.\n\n![Lab4](images/FinOps15.png)\n\nThe ‘Storage Summary’ dashboard shows the number of volumes (1), total monthly cost of these volumes (2), and potential monthly savings that can be realized (3). The ‘Unattached Storage’ bar (4) shows that about 7-8% of storage is currently unattached.\n\nLet’s take a deeper look at the specific volumes that can be reclaimed.\n\n## Reclaim waste\n\n4. On the Potential Savings dashboard, click SHOW ALL.\n\n![Lab4](images/FinOps16.png)\n\n\n5. Select the AZURE tab (1). Under the DELETE section of the left navigation bar, click Volumes (2).\n\n![Lab4](images/FinOps17.png)\n\nThe dashboard identifies the bank’s storage volumes that are unattached, including the number of days they have gone unused. On cloud, the lifecycles of the storage volumes are not intentionally associated with the lifecycles of the compute instances. Volumes that are unattached for many days are good candidates to reclaim and gain some savings. The data for each cloud provider appears on a separate tab. This dashboard displays the bank’s potential savings from Azure, assuming they take all the recommended actions.\n\nTurbonomic eliminates the need to hop between various cloud provider consoles. For example, we could also conveniently analyze storage usage in AWS or GCP by simply clicking the appropriate tab.\n\n6. Select the AWS tab (1). Under the DELETE section of the left navigation bar, click Volumes (2).\n\n![Lab4](images/FinOps18.png)\n\nJust by switching tabs, the bank can now see the potential savings from AWS storage, assuming they take all the recommended actions.\nOn the AWS tab, select a row and click the corresponding DETAILS button (3).\n\n7. Point out the details under ACTION ESSENTIALS on the Action Details panel, as highlighted in the screenshot and narration below.\n\n![Lab4](images/FinOps19.png)\n\nThe Action Details panel provides the bank with supporting details behind the recommendation. Under the ‘Action Essentials’ section, it also shows whether the action can be taken immediately, whether downtime is required, and whether the action is manually reversible once taken. Click \"Execute Action.\"\n\nNow let’s examine the bank’s cost savings opportunities from moving volumes to alternate storage types that are a better fit for the workloads at hand.\n\n## Select the right type of storage for the workloads\n\nThe bank needs to choose the right storage volume for their workloads. Capacity and performance are two fundamental factors around which these choices should be made. We’ll see how even if wrong initial choices are made, the Turbonomic platform will detect these optimization and cost reduction opportunities using its continuous feedback loop.\n\n8. Under the SCALE category of the left navigation bar, select Volumes.\n\n![Lab4](images/FinOps20.png)\n\nWe can immediately see the various scale options, along with the bank’s projected savings.\n\n9. Click DETAILS on the first row.\n\n![Lab4](images/FinOps21.png)\n\n10. Point out the details on the Action Details panel, as highlighted in the screenshot and narration below.\n\n![Lab4](images/FinOps22.png)\n![Lab4](images/FinOps23.png)\n\nWe can see that this particular volume is underutilized from both IOPS (1) and throughput (2) perspectives. Based on the actual utilization pattern of this workload, Turbonomic’s analytics show that this workload does not need a GP3 and that the performance requirements of the workload can be met with a cheaper ST1 storage tier. This workload does not need the provisioned 3,000 IOPS and can get by with a much lower 130 IOPS (Second Screenshot). We therefore see that the storage capacity was overprovisioned, at a cost that was 8-9% too high. Turbonomic’s analytics engine computes the projected cost savings (3 - First screenshot).\n\nBy analyzing and understanding the data access patterns of their workloads, the bank can make cost-efficient trade-offs about their storage choices, including the storage type, capacity, and IOPS. Click \"Execute Action\"\n","fileAbsolutePath":"/Users/brandonwu/Documents/PTS/Gatsby/Turbonomic-2Day-Partner-Workshop/src/pages/Labs/Lab4-finops.mdx"}}},
    "staticQueryHashes": ["1364590287","137577622","2102389209","2456312558","2746626797","3018647132","3037994772","768070550"]}